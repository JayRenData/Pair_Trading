{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2294803",
   "metadata": {},
   "source": [
    "shift +cmd+ i to bring the copilot chat\n",
    "\n",
    "Ornstein-Uhlenbeck (OU) process:\n",
    "\n",
    "It is a popular stochastic differential equation (SDE) to model mean-reverting spreads between two correlated assets.\n",
    "\n",
    "Before fitting an OU process, ensure that the two assets are cointegrated (i.e., their spread is mean-reverting).\n",
    "\n",
    "Common methods:\n",
    "Engle-Granger Test (ADF test on residuals of a linear regression).\n",
    "Johansen Test (for multiple assets).\n",
    "\n",
    "$$\n",
    "dc_t = \\kappa (\\theta - c_t)\\,dt + \\sigma\\,dW_t\n",
    "$$\n",
    "\n",
    "\n",
    "Model the spread as a discrete-time OU process:\n",
    "$$\n",
    "\\text{Spread}_{t+1} = a + b \\cdot \\text{Spread}_t + \\eta_t\n",
    "$$\n",
    "Estimate parameters a and b using linear regression of \n",
    "$$\n",
    "\\text{Spread}_{t+1} on  \n",
    "\n",
    "\\text{Spread}_t. \n",
    "$$\n",
    "Then, compute the OU parameters:\n",
    "\t‚Ä¢\tMean reversion rate (Œ∫): \n",
    "    $$\n",
    "    \\kappa = -\\ln(b) / \\Delta t\n",
    "    $$\n",
    "\t‚Ä¢\tLong-term mean (Œ∏): \n",
    "    $$\n",
    "    \\theta = a / (1 - b)\n",
    "    $$\n",
    "\t‚Ä¢\tVolatility (œÉ): \n",
    "    $$\n",
    "    \\sigma = \\text{std}(\\eta_t) \\cdot \\sqrt{2\\kappa / (1 - b^2)}\n",
    "    $$\n",
    "Assume \n",
    "$$\n",
    "\\Delta t = 1/252 \n",
    "$$\n",
    "for daily data.\n",
    "\n",
    "When ADF P value =0.9499, it is much greate than 0.05, meaning we fail to reject null hypotheis, that time series has a unit root, i.e. it is non-stationary.\n",
    "\n",
    "stationary implies constant mean and variance, then we can say two stock are cointegrated\n",
    "\n",
    "Half - life=ln(2)/k, for instance, if k=74.43 for the data by minute, then half - life = 0.0093 years, or 0.0093 * (252 days) * (390 min) = 914 minutes, or 2.3 trading day\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{F_-(e)}{F_-‚Äô(e)} = \\frac{H^+(e) - e - c}{H^+‚Äô(e) - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76ba71",
   "metadata": {},
   "source": [
    "\n",
    "Great! Let‚Äôs walk through a visual and mathematical explanation of where the optimal entry threshold condition comes from ‚Äî using stochastic optimal stopping theory.\n",
    "\n",
    "We‚Äôll work step by step toward the equation:\n",
    "$$\n",
    "\\frac{F_-(e)}{F_-‚Äô(e)} = \\frac{H^+(e) - e - c}{H^+‚Äô(e) - 1}\n",
    "$$\n",
    "‚∏ª\n",
    "\n",
    "üß† Setup: Two-Level Optimal Stopping Problem\n",
    "\n",
    "We want to find the optimal time to enter a long position in a mean-reverting spread E_t, modeled by an Ornstein‚ÄìUhlenbeck (OU) process:\n",
    "$$\n",
    "dE_t = \\kappa(\\theta - E_t)dt + \\sigma dW_t\n",
    "$$\n",
    "There are two value functions:\n",
    "\n",
    "üîπ 1. Exit Value Function H^+(e)\n",
    "\n",
    "Once you enter the trade, your position has value:\n",
    "\t‚Ä¢\tIf the spread rises and hits the exit threshold \n",
    "\t$$\n",
    "\tE^*_{\\text{exit}}\n",
    "\t$$\n",
    "\t, you close out and receive E_t - c\n",
    "\t‚Ä¢\tIf it hasn‚Äôt yet, you wait ‚Äî and the value decays based on expected time to exit\n",
    "\n",
    "üîπ 2. Entry Value Function G^+(e)\n",
    "\n",
    "Before entering the trade, the agent chooses when to act. The value function is:\n",
    "$$\n",
    "G^+(e) = \\sup_\\tau \\mathbb{E}e \\left[ e^{-\\rho \\tau} \\left(H^+(E\\tau) - E_\\tau - c \\right) \\right]\n",
    "$$\n",
    "‚Ä¢\tYou pay \n",
    "$$\n",
    "E_\\tau + c (spread + transaction cost)\n",
    "$$\n",
    "‚Ä¢\tYou receive value \n",
    "$$\n",
    "H^+(E_\\tau) if you enter\n",
    "$$\n",
    "‚Ä¢\tYou discount at rate \n",
    "$$\n",
    "\\rho\n",
    "$$\n",
    "‚∏ª\n",
    "\n",
    "‚úèÔ∏è The Entry Problem: Smooth Pasting Condition\n",
    "\n",
    "In optimal stopping theory, the optimal entry threshold \n",
    "\n",
    "$$E^*_{\\text{entry}}\n",
    "$$\n",
    " satisfies:\n",
    "\t1.\tValue matching: \n",
    "\t$$\n",
    "\tG^+(e) = H^+(e) - e - c\n",
    "\t$$\n",
    "\t2.\tSmooth pasting: \n",
    "\t$$\n",
    "\t\\frac{dG^+}{de} = H^+‚Äô(e) - 1\n",
    "\t$$\n",
    "This ensures the value function is smooth at the boundary, avoiding arbitrage or sudden jumps in value. These two conditions are required for continuous fit and first-order optimality.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üîß Analytical Tools: Fundamental Solutions\n",
    "\n",
    "To solve the entry problem, we use:\n",
    "$$\n",
    "G^+(e) = A \\cdot F_-(e)\n",
    "$$\n",
    "Where:\n",
    "\t‚Ä¢\tF_-(e) is a solution to the homogeneous ODE (\\mathcal{L} - \\rho)f = 0,\n",
    "\t‚Ä¢\tIt‚Äôs defined as:\n",
    "$$\t\n",
    "F_-(e) = \\int_0^\\infty u^{\\rho/\\kappa - 1} \\exp\\left(-\\frac{1}{2}\\sigma^2 u + \\kappa(\\theta - e)u\\right) du\n",
    "$$\n",
    "Take derivative:\n",
    "$$\n",
    "G^+‚Äô(e) = A \\cdot F_-‚Äô(e)\n",
    "$$\n",
    "‚∏ª\n",
    "\n",
    "üß© Now: Apply Matching Conditions at e = E^*_{\\text{entry}}\n",
    "\n",
    "From value matching:\n",
    "$$\n",
    "G^+(e) = H^+(e) - e - c = A \\cdot F_-(e)\n",
    "$$\n",
    "From smooth pasting:\n",
    "$$\n",
    "G^+‚Äô(e) = H^+‚Äô(e) - 1 = A \\cdot F_-‚Äô(e)\n",
    "$$\n",
    "Now eliminate A by dividing the equations:\n",
    "$$\n",
    "\\frac{F_-(e)}{F_-‚Äô(e)} = \\frac{H^+(e) - e - c}{H^+‚Äô(e) - 1}\n",
    "$$\n",
    "‚úÖ This is the entry threshold equation that must be solved numerically.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üß† Intuition\n",
    "\t‚Ä¢\tLeft-hand side: describes the value of waiting, governed by the OU process dynamics.\n",
    "\t‚Ä¢\tRight-hand side: describes the gain from entering now.\n",
    "\n",
    "You solve for e where these two forces exactly balance ‚Äî this gives you the optimal entry level.\n",
    "\n",
    "‚∏ª\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5d85ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -2.5646\n",
      "ADF p-value: 0.1005\n",
      "Critical Values: {'1%': np.float64(-3.435170967430817), '5%': np.float64(-2.8636690928667523), '10%': np.float64(-2.5679035297726274)}\n",
      "‚ùå Residuals are non-stationary ‚áí no cointegration.\n",
      "Ticker           GOOGL        NVDA\n",
      "Date                              \n",
      "2025-05-23  168.470001  131.289993\n",
      "2025-05-27  172.899994  135.500000\n",
      "2025-05-28  172.360001  134.809998\n",
      "2025-05-29  171.860001  139.190002\n",
      "2025-05-30  171.740005  135.130005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#using AD fuller test to check for cointegration\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Download data (example: SPY vs. XLE)\n",
    "tickers = [\"GOOGL\", \"NVDA\"]\n",
    "data = yf.download(tickers, start=\"2020-01-01\", end=\"2025-12-31\")[\"Close\"]\n",
    "data = data.dropna()\n",
    "\n",
    "# ticker=['googl', 'aal']\n",
    "# tickers=[tik.upper() for tik in ticker]\n",
    "# data = price_data[tickers]\n",
    "\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "data.index = pd.to_datetime(data.index)\n",
    "#data = data.asfreq('min')  # 'T' = 1-minute frequency\n",
    "data = data.dropna()\n",
    "\n",
    "# Cointegration test using Engle-Granger 2-step method\n",
    "def check_cointegration(y, x):\n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    spread = y - model.predict(sm.add_constant(x))  # more robust\n",
    "    adf_stat, p_value, _, _, crit_values, _ = adfuller(spread)\n",
    "    \n",
    "    print(\"ADF Statistic:\", round(adf_stat, 4))\n",
    "    print(\"ADF p-value:\", round(p_value, 4))\n",
    "    print(\"Critical Values:\", crit_values)\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"‚úÖ Residuals are stationary ‚áí series are cointegrated.\")\n",
    "    else:\n",
    "        print(\"‚ùå Residuals are non-stationary ‚áí no cointegration.\")\n",
    "    \n",
    "    return spread, p_value\n",
    "\n",
    "# Run the test\n",
    "spread, p_value = check_cointegration(data[tickers[0]], data[tickers[1]])\n",
    "\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bfb6d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:61: IntegrationWarning:\n",
      "\n",
      "The integral is probably divergent, or slowly convergent.\n",
      "\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:61: IntegrationWarning:\n",
      "\n",
      "The algorithm does not converge.  Roundoff error is detected\n",
      "  in the extrapolation table.  It is assumed that the requested tolerance\n",
      "  cannot be achieved, and that the returned result (if full_output = 1) is \n",
      "  the best which can be obtained.\n",
      "\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:67: IntegrationWarning:\n",
      "\n",
      "The algorithm does not converge.  Roundoff error is detected\n",
      "  in the extrapolation table.  It is assumed that the requested tolerance\n",
      "  cannot be achieved, and that the returned result (if full_output = 1) is \n",
      "  the best which can be obtained.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  GOOGL   R-squared:                       0.719\n",
      "Model:                            OLS   Adj. R-squared:                  0.719\n",
      "Method:                 Least Squares   F-statistic:                     3479.\n",
      "Date:                Sat, 31 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        16:25:56   Log-Likelihood:                -5880.0\n",
      "No. Observations:                1360   AIC:                         1.176e+04\n",
      "Df Residuals:                    1358   BIC:                         1.177e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         92.2087      0.715    129.048      0.000      90.807      93.610\n",
      "NVDA           0.6787      0.012     58.980      0.000       0.656       0.701\n",
      "==============================================================================\n",
      "Omnibus:                       62.164   Durbin-Watson:                   0.016\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.000\n",
      "Skew:                           0.021   Prob(JB):                     2.26e-06\n",
      "Kurtosis:                       2.324   Cond. No.                         89.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:67: IntegrationWarning:\n",
      "\n",
      "The integral is probably divergent, or slowly convergent.\n",
      "\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:152: IntegrationWarning:\n",
      "\n",
      "The integral is probably divergent, or slowly convergent.\n",
      "\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:146: IntegrationWarning:\n",
      "\n",
      "The maximum number of subdivisions (100) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:146: IntegrationWarning:\n",
      "\n",
      "The integral is probably divergent, or slowly convergent.\n",
      "\n",
      "/var/folders/zv/byjsmvy90d57p6xyyc10dt240000gn/T/ipykernel_38667/1382386998.py:146: IntegrationWarning:\n",
      "\n",
      "The algorithm does not converge.  Roundoff error is detected\n",
      "  in the extrapolation table.  It is assumed that the requested tolerance\n",
      "  cannot be achieved, and that the returned result (if full_output = 1) is \n",
      "  the best which can be obtained.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Portfolio Value: $10000.00\n",
      "Total Return: 0.00%\n",
      "Trade Log:\n",
      "\n",
      "Entry Date   Exit Date    Action     Spread     Profit\n",
      "            E_entry_star  EntrySignal half_life     Spread\n",
      "Date                                                      \n",
      "2025-05-02           NaN        False  2.011671  -5.887292\n",
      "2025-05-05           NaN        False  1.145188  -5.245783\n",
      "2025-05-06           NaN        False  1.025476  -6.035765\n",
      "2025-05-07           NaN        False  0.898937 -20.274698\n",
      "2025-05-08           NaN        False  3.000985 -17.585098\n",
      "2025-05-09           NaN        False  2.148456 -18.626448\n",
      "2025-05-12           NaN        False  2.726304 -17.226041\n",
      "2025-05-13           NaN        False  2.380586 -20.859278\n",
      "2025-05-14           NaN        False  2.894785 -18.690928\n",
      "2025-05-15           NaN        False  2.183084 -19.754795\n",
      "2025-05-16           NaN        False   1.76996 -17.911640\n",
      "2025-05-19           NaN        False  1.148492 -17.677033\n",
      "2025-05-20           NaN        False  0.600762 -19.429403\n",
      "2025-05-21           NaN        False  0.489944 -13.098413\n",
      "2025-05-22           NaN        False  0.403039 -11.487452\n",
      "2025-05-23           NaN        False  2.052665 -12.842277\n",
      "2025-05-27           NaN        False   2.14722 -11.269520\n",
      "2025-05-28           NaN        False  2.997217 -11.341225\n",
      "2025-05-29           NaN        False  3.220447 -14.813834\n",
      "2025-05-30           NaN        False  1.659742 -12.178401\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# OU estimator is dynamically estimated using a rolling window of 30 days.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import root_scalar\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Step 1: Download historical data\n",
    "tickers = [\"GOOGL\", \"NVDA\"]\n",
    "data = yf.download(tickers, start=\"2020-01-01\", end=\"2025-12-25\")[\"Close\"]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Step 2: Construct spread using OLS\n",
    "X = sm.add_constant(data[tickers[1]])\n",
    "model = OLS(data[tickers[0]], X).fit()\n",
    "spread = data[tickers[0]] - model.predict(X)\n",
    "# spead is the residual: actual appl price - predicted appl price\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Step 3: Estimate OU parameters, adjusting window size\n",
    "\n",
    "def estimate_ou_params(spread, window=10):\n",
    "    params = pd.DataFrame(index=spread.index, columns=[\"kappa\", \"theta\", \"sigma\", \"half_life\"])\n",
    "    dt = 1 / 252  # daily frequency\n",
    "    for i in range(window, len(spread)):\n",
    "        current_spread = spread.iloc[i - window:i]\n",
    "        X_t = current_spread[:-1].values\n",
    "        dX = np.diff(current_spread.values)\n",
    "        model = sm.OLS(dX, sm.add_constant(X_t)).fit()\n",
    "        a, b = model.params\n",
    "        resid_std = np.std(model.resid, ddof=1)\n",
    "        kappa = -b\n",
    "        theta = -a / b if b != 0 else np.mean(current_spread)\n",
    "        sigma = resid_std / np.sqrt(dt)\n",
    "        half_life = np.log(2) / kappa if kappa > 0 else np.inf\n",
    "        params.iloc[i] = [kappa, theta, sigma, half_life]\n",
    "    return params.dropna()\n",
    "\n",
    "ou_params = estimate_ou_params(spread)\n",
    "\n",
    "# --- Step 4: Combine OU params and compute Z-score ---\n",
    "spread_df = pd.DataFrame({\"Spread\": spread})\n",
    "spread_df = spread_df.merge(ou_params, left_index=True, right_index=True, how=\"inner\")\n",
    "spread_df[\"ZScore\"] = (spread_df[\"Spread\"] - spread_df[\"Spread\"].rolling(30).mean()) / spread_df[\"Spread\"].rolling(30).std()\n",
    "spread_df.dropna(inplace=True)\n",
    "\n",
    "# --- Step 5: Define F_minus and F_minus_prime with safety ---\n",
    "def safe_exp(x):\n",
    "    return np.exp(np.clip(x, -700, 700))  # prevent overflow\n",
    "\n",
    "def F_minus(e, kappa, theta, sigma, rho, upper_limit=20):\n",
    "    exponent = rho / kappa - 1\n",
    "    integrand = lambda u: u**max(exponent, -50) * safe_exp(-0.5 * sigma**2 * u + kappa * (theta - e) * u)\n",
    "    result, _ = quad(integrand, 0, upper_limit, limit=100)\n",
    "    return result\n",
    "\n",
    "def F_minus_prime(e, kappa, theta, sigma, rho, upper_limit=20):\n",
    "    exponent = rho / kappa\n",
    "    integrand = lambda u: -kappa * u**max(exponent, -50) * safe_exp(-0.5 * sigma**2 * u + kappa * (theta - e) * u)\n",
    "    result, _ = quad(integrand, 0, upper_limit, limit=100)\n",
    "    return result\n",
    "\n",
    "# --- Step 6: Compute F_minus and F_minus_prime over time ---\n",
    "rho = 0.1  # discount rate\n",
    "\n",
    "f_vals = []\n",
    "f_prime_vals = []\n",
    "\n",
    "for idx, row in spread_df.iterrows():\n",
    "    try:\n",
    "        f_val = F_minus(row[\"Spread\"], row[\"kappa\"], row[\"theta\"], row[\"sigma\"], rho)\n",
    "        f_prime_val = F_minus_prime(row[\"Spread\"], row[\"kappa\"], row[\"theta\"], row[\"sigma\"], rho)\n",
    "    except:\n",
    "        f_val, f_prime_val = np.nan, np.nan\n",
    "    f_vals.append(f_val)\n",
    "    f_prime_vals.append(f_prime_val)\n",
    "\n",
    "spread_df[\"F_minus\"] = f_vals\n",
    "spread_df[\"F_minus_prime\"] = f_prime_vals\n",
    "\n",
    "# Step 7: Define transaction cost and dynamic exit level\n",
    "c = 0.5  # example transaction cost\n",
    "spread_df[\"E_exit_star\"] = spread_df[\"Spread\"].rolling(60).max() * 0.8  # dynamic heuristic exit level (e.g., 80% of recent max)\n",
    "\n",
    "# Step 8: Define dynamic H_exit and H_exit_prime functions per row\n",
    "\n",
    "def compute_H_exit(e, e_star, kappa, c):\n",
    "    if e >= e_star:\n",
    "        return e - c\n",
    "    else:\n",
    "        return (e_star - c) * np.exp(kappa * (e - e_star)) + c\n",
    "\n",
    "def compute_H_exit_prime(e, e_star, kappa, c):\n",
    "    if e >= e_star:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return (e_star - c) * kappa * np.exp(kappa * (e - e_star))\n",
    "\n",
    "# Step 9: Apply H_exit and H_exit_prime across time using OU params\n",
    "H_vals = []\n",
    "H_prime_vals = []\n",
    "\n",
    "for idx, row in spread_df.iterrows():\n",
    "    try:\n",
    "        e = row[\"Spread\"]\n",
    "        e_star = row[\"E_exit_star\"]\n",
    "        kappa = row[\"kappa\"]\n",
    "        h_val = compute_H_exit(e, e_star, kappa, c)\n",
    "        h_prime_val = compute_H_exit_prime(e, e_star, kappa, c)\n",
    "    except:\n",
    "        h_val, h_prime_val = np.nan, np.nan\n",
    "    H_vals.append(h_val)\n",
    "    H_prime_vals.append(h_prime_val)\n",
    "\n",
    "spread_df[\"H_exit\"] = H_vals\n",
    "spread_df[\"H_exit_prime\"] = H_prime_vals\n",
    "\n",
    "# Step 10: Solve for entry threshold using root_scalar\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "entry_thresholds = []\n",
    "\n",
    "for idx, row in spread_df.iterrows():\n",
    "    try:\n",
    "        e_star = row[\"E_exit_star\"]\n",
    "        kappa = row[\"kappa\"]\n",
    "        theta = row[\"theta\"]\n",
    "        sigma = row[\"sigma\"]\n",
    "        \n",
    "        # Skip invalid rows\n",
    "        if pd.isnull([e_star, kappa, theta, sigma]).any() or kappa <= 0 or sigma <= 0:\n",
    "            entry_thresholds.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        # Local F_minus and F_minus_prime functions using that day's params\n",
    "        def Fm(e):\n",
    "            exponent = rho / kappa - 1\n",
    "            integrand = lambda u: u**max(exponent, -50) * np.exp(np.clip(-0.5 * sigma**2 * u + kappa * (theta - e) * u, -700, 700))\n",
    "            result, _ = quad(integrand, 0, 20, limit=100)\n",
    "            return result\n",
    "\n",
    "        def Fm_prime(e):\n",
    "            exponent = rho / kappa\n",
    "            integrand = lambda u: -kappa * u**max(exponent, -50) * np.exp(np.clip(-0.5 * sigma**2 * u + kappa * (theta - e) * u, -700, 700))\n",
    "            result, _ = quad(integrand, 0, 20, limit=100)\n",
    "            return result\n",
    "        \n",
    "        # H_exit and derivative for this specific day\n",
    "        def H(e):\n",
    "            if e >= e_star:\n",
    "                return e - c\n",
    "            else:\n",
    "                return (e_star - c) * np.exp(kappa * (e - e_star)) + c\n",
    "\n",
    "        def H_prime(e):\n",
    "            if e >= e_star:\n",
    "                return 1.0\n",
    "            else:\n",
    "                return (e_star - c) * kappa * np.exp(kappa * (e - e_star))\n",
    "        \n",
    "        # Entry threshold equation\n",
    "        def entry_eq(E):\n",
    "            lhs = Fm(E) / Fm_prime(E)\n",
    "            rhs_num = H(E) - E - c\n",
    "            rhs_denom = H_prime(E) - 1\n",
    "            if rhs_denom == 0:\n",
    "                return np.inf\n",
    "            return lhs - (rhs_num / rhs_denom)\n",
    "        \n",
    "        # Try solving root within valid domain\n",
    "        bracket_low = spread.min()\n",
    "        bracket_high = e_star - 0.01\n",
    "        \n",
    "        if bracket_high <= bracket_low:\n",
    "            entry_thresholds.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        sol = root_scalar(entry_eq, bracket=[bracket_low, bracket_high], method='brentq')\n",
    "        entry_thresholds.append(sol.root if sol.converged else np.nan)\n",
    "\n",
    "    except Exception as e:\n",
    "        entry_thresholds.append(np.nan)\n",
    "\n",
    "spread_df[\"E_entry_star\"] = entry_thresholds\n",
    "spread_df[\"EntrySignal\"] = spread_df[\"Spread\"] < spread_df[\"E_entry_star\"]\n",
    "\n",
    "# This loop uses the OU parameters per day to compute E_entry_star.\n",
    "# It gives you a dynamic entry threshold for every time index (row in spread_df) where the OU estimation is valid.\n",
    "# You can now use Spread < E_entry_star as a buy signal.\n",
    "\n",
    "# Step 11: Simulate trading using dynamic thresholds and OU signals\n",
    "position = 0\n",
    "entry_price = 0\n",
    "initial_cash = 10000\n",
    "cash = initial_cash\n",
    "pnl_history = []\n",
    "trade_log = []\n",
    "\n",
    "for date, row in spread_df.iterrows():\n",
    "    e = row[\"Spread\"]\n",
    "    z = row[\"ZScore\"]\n",
    "    e_entry_star = row.get(\"E_entry_star\", np.nan)\n",
    "    e_exit_star = row.get(\"E_exit_star\", np.nan)\n",
    "\n",
    "    if pd.notna(e_entry_star) and pd.notna(e_exit_star):\n",
    "        if position == 0 and e <= e_entry_star and z < -1.0:\n",
    "            # Enter trade\n",
    "            position = 1\n",
    "            entry_price = e\n",
    "            entry_date = date\n",
    "            trade_log.append([entry_date.strftime(\"%Y-%m-%d\"), \"\", \"ENTER\", round(e, 2), \"\"])\n",
    "\n",
    "        elif position == 1 and e >= e_exit_star and z > 0.5:\n",
    "            # Exit trade\n",
    "            position = 0\n",
    "            profit = e - entry_price\n",
    "            cash += profit\n",
    "            exit_date = date\n",
    "            trade_log[-1][1] = exit_date.strftime(\"%Y-%m-%d\")\n",
    "            trade_log[-1][-1] = round(profit, 2)\n",
    "\n",
    "    # Mark-to-market P&L\n",
    "    if position == 0:\n",
    "        pnl_history.append(cash)\n",
    "    else:\n",
    "        pnl_history.append(cash + (e - entry_price))\n",
    "\n",
    "# Store final P&L and trade logs\n",
    "spread_df[\"PnL\"] = pnl_history\n",
    "final_value = pnl_history[-1]\n",
    "total_return = (final_value - initial_cash) / initial_cash * 100\n",
    "\n",
    "print(f\"Final Portfolio Value: ${final_value:.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "\n",
    "trade_df = pd.DataFrame(trade_log, columns=[\"EntryDate\", \"ExitDate\", \"Action\", \"EntrySpread\", \"Profit\"])\n",
    "\n",
    "# Create a three-row subplot (Prices, Spread, P&L)\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\n",
    "        f\"{tickers[0]} and {tickers[1]} Prices\",\n",
    "        \"Spread and Trade Points with Z-Score Filter\",\n",
    "        f\"Cumulative Profit & Loss (Final Value: ${final_value:,.2f})\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Row 1: Price Plot ---\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data.index, y=data[tickers[0]],\n",
    "        mode=\"lines\", name=tickers[0], line=dict(color=\"blue\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî \" + tickers[0] + \": %{y:.2f}<extra></extra>\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=data.index, y=data[tickers[1]],\n",
    "        mode=\"lines\", name=tickers[1], line=dict(color=\"orange\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî \" + tickers[1] + \": %{y:.2f}<extra></extra>\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# --- Row 2: Spread Plot with Dynamic Entry/Exit Thresholds and Z-Score ---\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=spread_df.index, y=spread_df[\"Spread\"],\n",
    "        mode=\"lines\", name=\"Spread\", line=dict(color=\"blue\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî Spread: %{y:.2f}<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=spread_df.index, y=spread_df[\"E_entry_star\"],\n",
    "        mode=\"lines\", name=\"Dynamic Entry Threshold\",\n",
    "        line=dict(dash=\"dash\", color=\"green\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî Entry*: %{y:.2f}<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=spread_df.index, y=spread_df[\"E_exit_star\"],\n",
    "        mode=\"lines\", name=\"Dynamic Exit Threshold\",\n",
    "        line=dict(dash=\"dash\", color=\"red\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî Exit*: %{y:.2f}<extra></extra>\"\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=spread_df.index, y=spread_df[\"ZScore\"],\n",
    "        mode=\"lines\", name=\"Z-Score\",\n",
    "        line=dict(color=\"purple\", dash=\"dot\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî Z: %{y:.2f}<extra></extra>\",\n",
    "        yaxis=\"y2\"  # Reuse primary y-axis for simplicity or define a secondary one\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "# --- Row 3: Cumulative P&L Plot ---\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=spread_df.index, y=pnl_history,\n",
    "        mode=\"lines\", name=\"Cumulative P&L\", line=dict(color=\"black\"),\n",
    "        hovertemplate=\"%{x|%b %d} ‚Äî P&L: %{y:,.2f}<extra></extra>\"\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# --- Layout ---\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    title_text=\"Pairs Trading Analysis: Price, Spread, and P&L\",\n",
    "    xaxis=dict(title=\"Date\", tickformat=\"%b %d\"),\n",
    "    xaxis2=dict(title=\"Date\", tickformat=\"%b %d\"),\n",
    "    xaxis3=dict(title=\"Date\", tickformat=\"%b %d\"),\n",
    "    yaxis=dict(title=f\"{tickers[0]} / {tickers[1]} Price\"),\n",
    "    yaxis2=dict(title=\"Spread\"),\n",
    "    yaxis3=dict(title=\"Account Value\"),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Add trade entry/exit markers to Spread Plot\n",
    "for trade in trade_log:\n",
    "    entry_date = trade[0]\n",
    "    exit_date = trade[1]\n",
    "    entry_val = spread_df.loc[entry_date][\"Spread\"] if entry_date in spread_df.index else None\n",
    "    exit_val = spread_df.loc[exit_date][\"Spread\"] if exit_date in spread_df.index else None\n",
    "\n",
    "    if entry_val:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[entry_date], y=[entry_val],\n",
    "            mode=\"markers+text\", name=\"Trade Entry\",\n",
    "            marker=dict(symbol=\"triangle-up\", color=\"green\", size=10),\n",
    "            text=[\"Entry\"], textposition=\"top center\"\n",
    "        ), row=2, col=1)\n",
    "\n",
    "    if exit_val:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[exit_date], y=[exit_val],\n",
    "            mode=\"markers+text\", name=\"Trade Exit\",\n",
    "            marker=dict(symbol=\"triangle-down\", color=\"red\", size=10),\n",
    "            text=[\"Exit\"], textposition=\"bottom center\"\n",
    "        ), row=2, col=1)\n",
    "\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 10: Print trade log\n",
    "print(\"Trade Log:\\n\")\n",
    "print(f\"{'Entry Date':<12} {'Exit Date':<12} {'Action':<8} {'Spread':>8} {'Profit':>10}\")\n",
    "for trade in trade_log:\n",
    "    print(f\"{trade[0]:<12} {trade[1]:<12} {trade[2]:<8} {trade[3]:>8.3f} {str(trade[4]):>10}\")\n",
    "\n",
    "# --- Output Preview ---\n",
    "print(spread_df[[\"E_entry_star\", \"EntrySignal\", \"half_life\", \"Spread\"]].tail(20)) # Show last 20 rows of the spread DataFrame with OU params and Z-scores\n",
    "print(trade_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
